{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando métricas para o aspecto: organization_and_clarity\n",
      "Calculando métricas para o aspecto: use_of_examples\n",
      "Calculando métricas para o aspecto: argumentation\n",
      "Calculando métricas para o aspecto: coherence\n",
      "Calculando métricas para o aspecto: persuasion\n",
      "Calculando métricas para o aspecto: engagement\n",
      "Calculando métricas para o aspecto: adaptability\n",
      "Calculando métricas para o aspecto: preparation\n",
      "Calculando métricas para o aspecto: subject_mastery\n",
      "\n",
      "Resultados por aspecto:\n",
      "- organization_and_clarity: ICC = 0.545, Pearson = 0.467, Spearman = 0.486\n",
      "- use_of_examples: ICC = 0.570, Pearson = 0.471, Spearman = 0.480\n",
      "- argumentation: ICC = 0.502, Pearson = 0.472, Spearman = 0.460\n",
      "- coherence: ICC = 0.574, Pearson = 0.386, Spearman = 0.405\n",
      "- persuasion: ICC = 0.499, Pearson = 0.522, Spearman = 0.519\n",
      "- engagement: ICC = 0.599, Pearson = 0.603, Spearman = 0.598\n",
      "- adaptability: ICC = 0.579, Pearson = 0.439, Spearman = 0.447\n",
      "- preparation: ICC = 0.613, Pearson = 0.484, Spearman = 0.511\n",
      "- subject_mastery: ICC = 0.663, Pearson = 0.527, Spearman = 0.525\n",
      "\n",
      "Médias gerais:\n",
      "ICC médio: 0.571\n",
      "Correlação de Pearson média: 0.486\n",
      "Correlação de Spearman média: 0.492\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pingouin as pg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Carregar o JSON de um arquivo\n",
    "with open('judge_evaluations.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Lista de aspectos a serem avaliados\n",
    "all_aspects = [\n",
    "    \"organization_and_clarity\", \"use_of_examples\", \"argumentation\", \"coherence\",\n",
    "    \"persuasion\", \"engagement\", \"adaptability\", \"preparation\", \"subject_mastery\"\n",
    "]\n",
    "\n",
    "# Função para extrair a matriz\n",
    "def extract_aspect_matrix(json_data, aspect):\n",
    "    \"\"\"\n",
    "    Converte avaliações de um critério específico em uma matriz para cálculo de ICC e outras correlações.\n",
    "    Mantém as notas numéricas.\n",
    "    \"\"\"\n",
    "    evaluators = {}\n",
    "    for entry in json_data:\n",
    "        debate_id = entry[\"debate_id\"]\n",
    "        evaluator_id = entry[\"evaluator\"]\n",
    "        if debate_id not in evaluators:\n",
    "            evaluators[debate_id] = {}\n",
    "        for debater in entry[\"debaters\"]:\n",
    "            name = debater[\"name\"]\n",
    "            score = debater[\"evaluation_aspects\"][aspect]\n",
    "            if name not in evaluators[debate_id]:\n",
    "                evaluators[debate_id][name] = {}\n",
    "            evaluators[debate_id][name][evaluator_id] = score\n",
    "\n",
    "    # Construir matriz para avaliação\n",
    "    matrix = []\n",
    "    for debate_id, debaters in evaluators.items():\n",
    "        for name, scores in debaters.items():\n",
    "            matrix.append([scores.get(evaluator, None) for evaluator in sorted(scores.keys())])\n",
    "    return matrix\n",
    "\n",
    "# Resultados agregados\n",
    "results = {\"ICC\": [], \"Pearson\": [], \"Spearman\": []}\n",
    "\n",
    "# Iterar por todos os aspectos e calcular métricas\n",
    "for aspect in all_aspects:\n",
    "    print(f\"Calculando métricas para o aspecto: {aspect}\")\n",
    "    # Extrair matriz para o aspecto\n",
    "    matrix = extract_aspect_matrix(data, aspect)\n",
    "    \n",
    "    # Transpor a matriz\n",
    "    matrix = list(map(list, zip(*matrix)))\n",
    "    \n",
    "    # Preparar dados para o ICC\n",
    "    df = pd.DataFrame(matrix)\n",
    "    df_long = pd.melt(df, var_name=\"rater\", value_name=\"rating\")\n",
    "    df_long[\"target\"] = np.tile(df.index, len(df.columns))\n",
    "    \n",
    "    # Calcular ICC\n",
    "    icc_result = pg.intraclass_corr(data=df_long, targets=\"target\", raters=\"rater\", ratings=\"rating\")\n",
    "    icc_mean = icc_result[\"ICC\"].mean()\n",
    "    results[\"ICC\"].append(icc_mean)\n",
    "    \n",
    "    # Calcular correlação de Pearson\n",
    "    pearson_corrs = []\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(i + 1, len(matrix)):\n",
    "            corr, _ = pearsonr(matrix[i], matrix[j])\n",
    "            pearson_corrs.append(corr)\n",
    "    results[\"Pearson\"].append(np.mean(pearson_corrs))\n",
    "    \n",
    "    # Calcular correlação de Spearman\n",
    "    spearman_corrs = []\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(i + 1, len(matrix)):\n",
    "            corr, _ = spearmanr(matrix[i], matrix[j])\n",
    "            spearman_corrs.append(corr)\n",
    "    results[\"Spearman\"].append(np.mean(spearman_corrs))\n",
    "\n",
    "# Calcular médias gerais\n",
    "icc_overall = np.mean(results[\"ICC\"])\n",
    "pearson_overall = np.mean(results[\"Pearson\"])\n",
    "spearman_overall = np.mean(results[\"Spearman\"])\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nResultados por aspecto:\")\n",
    "for idx, aspect in enumerate(all_aspects):\n",
    "    print(f\"- {aspect}: ICC = {results['ICC'][idx]:.3f}, \"\n",
    "          f\"Pearson = {results['Pearson'][idx]:.3f}, \"\n",
    "          f\"Spearman = {results['Spearman'][idx]:.3f}\")\n",
    "\n",
    "print(\"\\nMédias gerais:\")\n",
    "print(f\"ICC médio: {icc_overall:.3f}\")\n",
    "print(f\"Correlação de Pearson média: {pearson_overall:.3f}\")\n",
    "print(f\"Correlação de Spearman média: {spearman_overall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Médias gerais: {'mean_absolute': np.float64(0.9209276786609468), 'mean_random': np.float64(0.9243645434881258), 'mean_fixed': np.float64(0.9590270365514226)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_aspect_matrix(json_data, aspect):\n",
    "    evaluators = {}\n",
    "    for entry in json_data:\n",
    "        debate_id = entry[\"debate_id\"]\n",
    "        evaluator_id = entry[\"evaluator\"]\n",
    "        if debate_id not in evaluators:\n",
    "            evaluators[debate_id] = {}\n",
    "        for debater in entry[\"debaters\"]:\n",
    "            name = debater[\"name\"]\n",
    "            score = debater[\"evaluation_aspects\"][aspect]\n",
    "            if name not in evaluators[debate_id]:\n",
    "                evaluators[debate_id][name] = {}\n",
    "            evaluators[debate_id][name][evaluator_id] = score\n",
    "\n",
    "    matrix = []\n",
    "    for debate_id, debaters in evaluators.items():\n",
    "        for name, scores in debaters.items():\n",
    "            matrix.append([scores.get(evaluator, None) for evaluator in sorted(scores.keys())])\n",
    "    return matrix\n",
    "\n",
    "# Função para calcular ICC por tipo e aspecto\n",
    "def calculate_icc_metrics(json_data, aspects):\n",
    "    results = []\n",
    "\n",
    "    for aspect in aspects:\n",
    "        matrix = extract_aspect_matrix(json_data, aspect)\n",
    "        matrix = list(map(list, zip(*matrix)))\n",
    "\n",
    "        # Preparar os dados para ICC\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df_long = pd.melt(df, var_name=\"rater\", value_name=\"rating\")\n",
    "        df_long[\"target\"] = np.tile(df.index, len(df.columns))\n",
    "\n",
    "        # Calcular ICC\n",
    "        icc_result = pg.intraclass_corr(data=df_long, targets=\"target\", raters=\"rater\", ratings=\"rating\")\n",
    "\n",
    "        # Extração dos valores específicos\n",
    "        avg_absolute = icc_result.loc[icc_result[\"Type\"] == \"ICC1k\", \"ICC\"].values[0]\n",
    "        avg_random = icc_result.loc[icc_result[\"Type\"] == \"ICC2k\", \"ICC\"].values[0]\n",
    "        avg_fixed = icc_result.loc[icc_result[\"Type\"] == \"ICC3k\", \"ICC\"].values[0]\n",
    "\n",
    "        results.append({\n",
    "            \"aspect\": aspect,\n",
    "            \"average_absolute\": avg_absolute,\n",
    "            \"average_random\": avg_random,\n",
    "            \"average_fixed\": avg_fixed,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Calcular resultados (exemplo com dados fictícios no JSON \"data\")\n",
    "# results_df = calculate_icc_metrics(data, aspects)\n",
    "# print(results_df)\n",
    "\n",
    "# Função para calcular médias gerais\n",
    "def calculate_overall_means(results_df):\n",
    "    mean_absolute = results_df[\"average_absolute\"].mean()\n",
    "    mean_random = results_df[\"average_random\"].mean()\n",
    "    mean_fixed = results_df[\"average_fixed\"].mean()\n",
    "    return {\n",
    "        \"mean_absolute\": mean_absolute,\n",
    "        \"mean_random\": mean_random,\n",
    "        \"mean_fixed\": mean_fixed,\n",
    "    }\n",
    "\n",
    "\n",
    "aspects = [\n",
    "    \"organization_and_clarity\",\n",
    "    \"use_of_examples\",\n",
    "    \"argumentation\",\n",
    "    \"coherence\",\n",
    "    \"persuasion\",\n",
    "    \"engagement\",\n",
    "    \"adaptability\",\n",
    "    \"preparation\",\n",
    "    \"subject_mastery\"\n",
    "]\n",
    "\n",
    "# Calcular ICCs para todos os aspectos\n",
    "results_df = calculate_icc_metrics(data, aspects)\n",
    "\n",
    "# Calcular médias gerais dos tipos de ICCs\n",
    "overall_means = calculate_overall_means(results_df)\n",
    "print(\"Médias gerais:\", overall_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados indicam uma alta consistência entre os avaliadores quando consideramos as médias nos diferentes modelos de ICC:\n",
    "\n",
    "Interpretação dos resultados:\n",
    "Média do ICC (Average raters absolute): 0.921\n",
    "Isso mostra que, em média, há uma excelente confiabilidade absoluta ao considerar as avaliações de vários avaliadores combinados.\n",
    "\n",
    "Média do ICC (Average random raters): 0.924\n",
    "Indica que a confiabilidade permanece alta mesmo quando os avaliadores são considerados como aleatoriamente selecionados.\n",
    "\n",
    "Média do ICC (Average fixed raters): 0.959\n",
    "Este valor ainda maior reflete uma altíssima consistência entre os avaliadores fixos ao combinar suas avaliações.\n",
    "\n",
    "Conclusão:\n",
    "Essas métricas sugerem que, ao considerar a média das avaliações de vários avaliadores, a consistência é muito alta, o que valida a confiabilidade do método de avaliação usado. Agora, você pode usar esses dados como uma base sólida para justificar as análises comparativas entre métodos ou validar a qualidade dos avaliadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
